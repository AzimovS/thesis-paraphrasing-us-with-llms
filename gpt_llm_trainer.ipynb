{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Describe your model -> fine-tuned LLaMA 2\n",
        "By Matt Shumer (https://twitter.com/mattshumer_)\n",
        "\n",
        "The goal of this notebook is to experiment with a new way to make it very easy to build a task-specific model for your use-case.\n",
        "\n",
        "First, use the best GPU available (go to Runtime -> change runtime type)\n",
        "\n",
        "To create your model, just go to the first code cell, and describe the model you want to build in the prompt. Be descriptive and clear.\n",
        "\n",
        "Select a temperature (high=creative, low=precise), and the number of training examples to generate to train the model. From there, just run all the cells.\n",
        "\n",
        "You can change the model you want to fine-tune by changing `model_name` in the `Define Hyperparameters` cell."
      ],
      "metadata": {
        "id": "wM8MRkf8Dr94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt = \"A model that takes in a puzzle-like reasoning-heavy question in English, and responds with a well-reasoned, step-by-step thought out response in Spanish.\"\n",
        "# temperature = .4\n",
        "# number_of_examples = 100"
      ],
      "metadata": {
        "id": "R7WKZyxtpUPS"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install necessary libraries"
      ],
      "metadata": {
        "id": "AbrFgrhG_xYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.31.0 trl==0.4.7 textstat\n",
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    HfArgumentParser,\n",
        "    TrainingArguments,\n",
        "    pipeline,\n",
        "    logging,\n",
        ")\n",
        "from peft import LoraConfig, PeftModel\n",
        "from trl import SFTTrainer"
      ],
      "metadata": {
        "id": "lPG7wEPetFx2",
        "outputId": "1bb47407-8896-45cf-a4a9-014e2b6451c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/244.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/244.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.5/92.5 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.4/77.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.1/105.1 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m967.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uGDs4r5rrrAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming your dataset is stored in a CSV file named \"dataset.csv\"\n",
        "dataset = pd.read_csv(\"withparaphrased.csv\")\n",
        "len(dataset[dataset['Paraphrased User Story'] == 'ERROR'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRYHZrJHXngn",
        "outputId": "0d2d9770-6a17-4471-94de-66bab70abffc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "227"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming your dataset is stored in a CSV file named \"dataset.csv\"\n",
        "dataset = pd.read_csv(\"withparaphrased.csv\")\n",
        "\n",
        "dataset = dataset[dataset['Paraphrased User Story'] != 'ERROR']\n",
        "\n",
        "# Create a new column 'text' by concatenating values from selected columns\n",
        "dataset['prompt'] = \"Paraphrase the following user story: \" + dataset['User Story'] + \".\\n\"\n",
        "dataset['prompt'] += \"Based on the following metrics: \"\n",
        "flag = False\n",
        "for col in dataset.columns:\n",
        "    if col.startswith('diff'):\n",
        "        if flag:\n",
        "            dataset['prompt'] += ', '\n",
        "        flag = True\n",
        "        dataset['prompt'] += col + \": \" + dataset[col].astype(str)\n",
        "dataset['response'] = dataset['Paraphrased User Story']\n",
        "\n",
        "# Selecting the columns\n",
        "selected_columns = ['prompt'] + [col for col in dataset.columns if col.startswith('diff.')]\n",
        "\n",
        "# Creating a new DataFrame with selected columns\n",
        "selected_data = dataset[['prompt', 'response', 'User Story', 'Paraphrased User Story']]\n",
        "train_df = selected_data.sample(frac=0.5, random_state=42)\n",
        "test_df = selected_data.drop(train_df.index)\n",
        "\n",
        "train_df[:300].to_json('train.jsonl', orient='records', lines=True)\n",
        "test_df.to_json('test.jsonl', orient='records', lines=True)\n"
      ],
      "metadata": {
        "id": "NUVtkIforqsu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['prompt'][81]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "opv--6LC7TBp",
        "outputId": "935e1241-3189-41e1-e355-d36463f87e8b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Paraphrase the following user story: As a neuroscientist, I want to use echo state networks to model the dynamics of neural activity in the brain and predict the effects of different stimuli on brain function, so that I can better understand the relationship between neural activity and behavior..\\nBased on the following metrics: diff_total_characters: -12, diff_uppercase_characters: 0, diff_lowercase_characters: -14, diff_special_characters: 0, diff_numbers: 0, diff_blanks: 2, diff_number_of_words: 2, diff_average_length_of_words: -0.5876347135564375, diff_number_of_propositions: -1, diff_average_length_of_propositions: 22.5, diff_punctuation_characters: 0, diff_lowercase_words: 2, diff_uppercase_words: 1, diff_vocabulary_richness: -1, diff_number_of_urls: 0, diff_flesch_kincaid_grade_level: 6.399999999999999, diff_flesch_reading_ease: -5.919999999999998, diff_dale_chall_readability: -1.0500000000000007, diff_automated_readability_index: 8.599999999999998, diff_coleman_liau_index: -2.4800000000000004, diff_gunning_fog: 5.850000000000001, diff_smog_index: 0.0, diff_linsear_write_index: 14.75'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Hyperparameters"
      ],
      "metadata": {
        "id": "moVo0led-6tu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"NousResearch/llama-2-7b-chat-hf\" # use this if you have access to the official LLaMA 2 model \"meta-llama/Llama-2-7b-chat-hf\", though keep in mind you'll need to pass a Hugging Face key argument\n",
        "dataset_name = \"/content/train.jsonl\"\n",
        "new_model = \"llama-2-7b-custom\"\n",
        "lora_r = 64\n",
        "lora_alpha = 16\n",
        "lora_dropout = 0.1\n",
        "use_4bit = True\n",
        "bnb_4bit_compute_dtype = \"float16\"\n",
        "bnb_4bit_quant_type = \"nf4\"\n",
        "use_nested_quant = False\n",
        "output_dir = \"./results\"\n",
        "num_train_epochs = 1\n",
        "fp16 = False\n",
        "bf16 = False\n",
        "per_device_train_batch_size = 4\n",
        "per_device_eval_batch_size = 4\n",
        "gradient_accumulation_steps = 1\n",
        "gradient_checkpointing = True\n",
        "max_grad_norm = 0.3\n",
        "learning_rate = 2e-4\n",
        "weight_decay = 0.001\n",
        "optim = \"paged_adamw_32bit\"\n",
        "lr_scheduler_type = \"constant\"\n",
        "max_steps = -1\n",
        "warmup_ratio = 0.03\n",
        "group_by_length = True\n",
        "save_steps = 25\n",
        "logging_steps = 5\n",
        "max_seq_length = None\n",
        "packing = False\n",
        "device_map = {\"\": 0}"
      ],
      "metadata": {
        "id": "bqfbhUZI-4c_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Datasets and Train"
      ],
      "metadata": {
        "id": "F-J5p5KS_MZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "train_dataset = load_dataset('json', data_files='/content/train.jsonl', split=\"train\")\n",
        "valid_dataset = load_dataset('json', data_files='/content/test.jsonl', split=\"train\")\n",
        "\n",
        "# Preprocess datasets\n",
        "train_dataset_mapped = train_dataset.map(lambda examples: {'text': [f'<s>[INST]' + prompt + ' [/INST] ' + response + '</s>' for prompt, response in zip(examples['prompt'], examples['response'])]}, batched=True)\n",
        "valid_dataset_mapped = valid_dataset.map(lambda examples: {'text': [f'<s>[INST]' + prompt + ' [/INST] ' + response + '</s>' for prompt, response in zip(examples['prompt'], examples['response'])]}, batched=True)\n",
        "\n",
        "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=use_4bit,\n",
        "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
        "    bnb_4bit_compute_dtype=compute_dtype,\n",
        "    bnb_4bit_use_double_quant=use_nested_quant,\n",
        ")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=device_map\n",
        ")\n",
        "model.config.use_cache = False\n",
        "model.config.pretraining_tp = 1\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha=lora_alpha,\n",
        "    lora_dropout=lora_dropout,\n",
        "    r=lora_r,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "# Set training parameters\n",
        "training_arguments = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=num_train_epochs,\n",
        "    per_device_train_batch_size=per_device_train_batch_size,\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "    optim=optim,\n",
        "    save_steps=save_steps,\n",
        "    logging_steps=logging_steps,\n",
        "    learning_rate=learning_rate,\n",
        "    weight_decay=weight_decay,\n",
        "    fp16=fp16,\n",
        "    bf16=bf16,\n",
        "    max_grad_norm=max_grad_norm,\n",
        "    max_steps=max_steps,\n",
        "    warmup_ratio=warmup_ratio,\n",
        "    group_by_length=group_by_length,\n",
        "    lr_scheduler_type=lr_scheduler_type,\n",
        "    report_to=\"all\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=70  # Evaluate every 20 steps\n",
        ")\n",
        "# Set supervised fine-tuning parameters\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=train_dataset_mapped,\n",
        "    eval_dataset=valid_dataset_mapped,  # Pass validation dataset here\n",
        "    peft_config=peft_config,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments,\n",
        "    packing=packing,\n",
        ")\n",
        "trainer.train()\n",
        "trainer.model.save_pretrained(new_model)\n",
        "\n",
        "# Cell 4: Test the model\n",
        "# logging.set_verbosity(logging.CRITICAL)\n",
        "# prompt = f\"[INST]Write a function that reverses a string. [/INST]\" # replace the command here with something relevant to your task\n",
        "# pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)\n",
        "# result = pipe(prompt)\n",
        "# print(result[0]['generated_text'])"
      ],
      "metadata": {
        "id": "qf1qxbiF-x6p",
        "outputId": "0151a1d7-2f13-4ce0-8959-519c8eca13e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280,
          "referenced_widgets": [
            "3a4da5b74c8b4664aa39728156939af4",
            "62da50fe09b0444cbfba1015dff337d3",
            "851b2eede2cb4020a730bf1ac23013fb",
            "6310ebcb68e24bd9a07f05fc7ac7b70b",
            "754ebc1751894ee7ae333948dc1eed19",
            "2e2aafb99c714befb63b329774291141",
            "4888364854a548f7bccf997da151c0b8",
            "8fdbbbb08d1447d4a5457011433283cc",
            "8ea9b66de5434b6c859de40ebf248a52",
            "b291b073477449098884b5bb65b7e959",
            "eb49b88252ab441dabf857d64382a1d7",
            "2ea9b554a38749fc817db6ab539f5350",
            "ee649089e162496b9e16561278f44208",
            "f3660101f5464ac5be3e328ca56b22e4",
            "42149efd68474a75906d55bb91c82343",
            "c5481eb72f0d4c88b603a757eead5f82",
            "daaa3c804e424e51ada07e23eed13d4d",
            "a000807da3fc4f57875fada392b37d49",
            "1d7e9b510913443cb06ba73941d4a287",
            "99549adfaa6e455eb162b8aec81ebed8",
            "51d7a13830694dbba46975326c92d940",
            "c8e2fc07d1d241c8b2020b7079b29868"
          ]
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a4da5b74c8b4664aa39728156939af4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2887 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ea9b554a38749fc817db6ab539f5350"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [75/75 34:42, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.362200</td>\n",
              "      <td>0.370668</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run Inference"
      ],
      "metadata": {
        "id": "F6fux9om_c4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "prompt = f\"<s>[INST]Paraphrase the following user story: A researcher in computational biology is using backpropagation to train a machine learning algorithm to predict the likelihood of different genetic mutations leading to cancer. By analyzing large sets of genomic data, the algorithm is trained to identify the underlying genetic factors that contribute to cancer development..\\nBased on the following metrics: diff_total_characters: 9,diff_uppercase_characters: 0,diff_lowercase_characters: 8,diff_special_characters: 0,diff_numbers: 0,diff_blanks: 1,diff_number_of_words: 1,diff_average_length_of_words: 0.0453283996299722,diff_number_of_propositions: 0,diff_average_length_of_propositions: 0.5,diff_punctuation_characters: 0,diff_lowercase_words: 1,diff_uppercase_words: 0,diff_vocabulary_richness: 1,diff_number_of_urls: 0, [/INST]\" # replace the command here with something relevant to your task\n",
        "num_new_tokens = 100  # change to the number of new tokens you want to generate\n",
        "\n",
        "# Count the number of tokens in the prompt\n",
        "num_prompt_tokens = len(tokenizer(prompt)['input_ids'])\n",
        "\n",
        "# Calculate the maximum length for the generation\n",
        "max_length = num_prompt_tokens + num_new_tokens\n",
        "\n",
        "gen = pipeline('text-generation', model=model, tokenizer=tokenizer, max_length=max_length)\n",
        "result = gen(prompt)\n",
        "print(result[0]['generated_text'].replace(prompt, ''))"
      ],
      "metadata": {
        "id": "7hxQ_Ero2IJe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5baae5e-a5fd-4a78-f1cd-2a919cdebfde"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
            "pip install xformers.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1270: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A researcher in computational biology is utilizing backpropagation to train a machine learning model to predict the likelihood of various genetic mutations leading to cancer. By analyzing vast sets of genomic data, the algorithm is being taught to identify the underlying genetic factors that contribute to cancer development.</s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import re\n",
        "import textstat\n",
        "\n",
        "def total_characters(text):\n",
        "    return len(text)\n",
        "\n",
        "def uppercase_characters(text):\n",
        "    return sum(1 for char in text if char.isupper())\n",
        "\n",
        "def lowercase_characters(text):\n",
        "    return sum(1 for char in text if char.islower())\n",
        "\n",
        "def special_characters(text):\n",
        "    special_chars = \"!\\\"#$%&'()*+,-./:;<=>?@[\\\\]^_`{|}~\"\n",
        "    return sum(1 for char in text if char in special_chars)\n",
        "\n",
        "def numbers(text):\n",
        "    return sum(1 for char in text if char.isdigit())\n",
        "\n",
        "def blanks(text):\n",
        "    return sum(1 for char in text if char.isspace())\n",
        "\n",
        "def number_of_words(text):\n",
        "    return len(text.split())\n",
        "\n",
        "def average_length_of_words(text):\n",
        "    words = text.split()\n",
        "    total_length = sum(len(word) for word in words)\n",
        "    num_words = len(words)\n",
        "    if num_words == 0:\n",
        "        return 0\n",
        "    return total_length / num_words\n",
        "\n",
        "def number_of_propositions(text):\n",
        "    propositions = re.split(r'[.!?]+', text)\n",
        "    return len([prop for prop in propositions if prop.strip()])\n",
        "\n",
        "def average_length_of_propositions(text):\n",
        "    propositions = re.split(r'[.!?]+', text)\n",
        "    lengths = [len(prop.strip().split()) for prop in propositions if prop.strip()]\n",
        "    if lengths:\n",
        "        return sum(lengths) / len(lengths)\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def punctuation_characters(text):\n",
        "    return sum(1 for char in text if char in string.punctuation)\n",
        "\n",
        "def lowercase_words(text):\n",
        "    words = text.split()\n",
        "    return sum(1 for word in words if word.islower())\n",
        "\n",
        "def uppercase_words(text):\n",
        "    words = text.split()\n",
        "    return sum(1 for word in words if word.isupper())\n",
        "\n",
        "def vocabulary_richness(text):\n",
        "    words = text.lower().split()\n",
        "    unique_words = set(words)\n",
        "    dw = len(unique_words)\n",
        "    return dw\n",
        "\n",
        "def number_of_urls(text):\n",
        "    urls = re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', text)\n",
        "    return len(urls)\n",
        "\n",
        "def flesch_kincaid_grade_level(text):\n",
        "    return textstat.flesch_kincaid_grade(text)\n",
        "\n",
        "def flesch_reading_ease(text):\n",
        "    return textstat.flesch_reading_ease(text)\n",
        "\n",
        "def dale_chall_readability(text):\n",
        "    return textstat.dale_chall_readability_score(text)\n",
        "\n",
        "def automated_readability_index(text):\n",
        "    return textstat.automated_readability_index(text)\n",
        "\n",
        "def coleman_liau_index(text):\n",
        "    return textstat.coleman_liau_index(text)\n",
        "\n",
        "def gunning_fog(text):\n",
        "    return textstat.gunning_fog(text)\n",
        "\n",
        "def smog_index(text):\n",
        "    return textstat.smog_index(text)\n",
        "\n",
        "def linsear_write_index(text):\n",
        "    return textstat.linsear_write_formula(text)"
      ],
      "metadata": {
        "id": "g1AZWxf5HjM4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df"
      ],
      "metadata": {
        "id": "zBaMVAyt0dGr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "outputId": "c6c1df5c-5560-4454-b01b-203364e569ae"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 prompt  \\\n",
              "1     Paraphrase the following user story: As a mole...   \n",
              "2     Paraphrase the following user story: As a bioi...   \n",
              "3     Paraphrase the following user story: As a geno...   \n",
              "4     Paraphrase the following user story: A researc...   \n",
              "5     Paraphrase the following user story: As a cogn...   \n",
              "...                                                 ...   \n",
              "5985  Paraphrase the following user story: As a medi...   \n",
              "5986  Paraphrase the following user story: As a medi...   \n",
              "5988  Paraphrase the following user story: As a medi...   \n",
              "5991  Paraphrase the following user story: As a medi...   \n",
              "5996  Paraphrase the following user story: As a medi...   \n",
              "\n",
              "                                               response  \\\n",
              "1     As a molecular biologist, I want to utilize ac...   \n",
              "2     As a bioinformatics researcher, I want to leve...   \n",
              "3     As a genomics researcher, I want to utilize th...   \n",
              "4     A bioinformatics researcher is utilizing an Ad...   \n",
              "5     As a cognitive neuroscientist, I aim to levera...   \n",
              "...                                                 ...   \n",
              "5985  As a medical researcher, I want to use natural...   \n",
              "5986  As a medical researcher, I want to utilize Kle...   \n",
              "5988  As a medical researcher, I want to utilize lan...   \n",
              "5991  As a medical researcher, I want to use latent ...   \n",
              "5996  As a medical researcher, I desire leveraging t...   \n",
              "\n",
              "                                             User Story  \\\n",
              "1     As a molecular biologist, I want to use action...   \n",
              "2     As a bioinformatics researcher, I want to use ...   \n",
              "3     As a genomics researcher, I want to use the Ad...   \n",
              "4     A researcher in bioinformatics is using an Ada...   \n",
              "5     As a cognitive neuroscientist, I want to use a...   \n",
              "...                                                 ...   \n",
              "5985  As a medical researcher, I want to use keyword...   \n",
              "5986  As a medical researcher, I want to use kleene ...   \n",
              "5988  As a medical researcher, I want to use languag...   \n",
              "5991  As a medical researcher, I want to use latent ...   \n",
              "5996  As a medical researcher, I want to use learnin...   \n",
              "\n",
              "                                 Paraphrased User Story  \n",
              "1     As a molecular biologist, I want to utilize ac...  \n",
              "2     As a bioinformatics researcher, I want to leve...  \n",
              "3     As a genomics researcher, I want to utilize th...  \n",
              "4     A bioinformatics researcher is utilizing an Ad...  \n",
              "5     As a cognitive neuroscientist, I aim to levera...  \n",
              "...                                                 ...  \n",
              "5985  As a medical researcher, I want to use natural...  \n",
              "5986  As a medical researcher, I want to utilize Kle...  \n",
              "5988  As a medical researcher, I want to utilize lan...  \n",
              "5991  As a medical researcher, I want to use latent ...  \n",
              "5996  As a medical researcher, I desire leveraging t...  \n",
              "\n",
              "[2887 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3014ad0c-449e-41f1-af0e-0a8f13926b45\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>response</th>\n",
              "      <th>User Story</th>\n",
              "      <th>Paraphrased User Story</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Paraphrase the following user story: As a mole...</td>\n",
              "      <td>As a molecular biologist, I want to utilize ac...</td>\n",
              "      <td>As a molecular biologist, I want to use action...</td>\n",
              "      <td>As a molecular biologist, I want to utilize ac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Paraphrase the following user story: As a bioi...</td>\n",
              "      <td>As a bioinformatics researcher, I want to leve...</td>\n",
              "      <td>As a bioinformatics researcher, I want to use ...</td>\n",
              "      <td>As a bioinformatics researcher, I want to leve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Paraphrase the following user story: As a geno...</td>\n",
              "      <td>As a genomics researcher, I want to utilize th...</td>\n",
              "      <td>As a genomics researcher, I want to use the Ad...</td>\n",
              "      <td>As a genomics researcher, I want to utilize th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Paraphrase the following user story: A researc...</td>\n",
              "      <td>A bioinformatics researcher is utilizing an Ad...</td>\n",
              "      <td>A researcher in bioinformatics is using an Ada...</td>\n",
              "      <td>A bioinformatics researcher is utilizing an Ad...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Paraphrase the following user story: As a cogn...</td>\n",
              "      <td>As a cognitive neuroscientist, I aim to levera...</td>\n",
              "      <td>As a cognitive neuroscientist, I want to use a...</td>\n",
              "      <td>As a cognitive neuroscientist, I aim to levera...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5985</th>\n",
              "      <td>Paraphrase the following user story: As a medi...</td>\n",
              "      <td>As a medical researcher, I want to use natural...</td>\n",
              "      <td>As a medical researcher, I want to use keyword...</td>\n",
              "      <td>As a medical researcher, I want to use natural...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5986</th>\n",
              "      <td>Paraphrase the following user story: As a medi...</td>\n",
              "      <td>As a medical researcher, I want to utilize Kle...</td>\n",
              "      <td>As a medical researcher, I want to use kleene ...</td>\n",
              "      <td>As a medical researcher, I want to utilize Kle...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5988</th>\n",
              "      <td>Paraphrase the following user story: As a medi...</td>\n",
              "      <td>As a medical researcher, I want to utilize lan...</td>\n",
              "      <td>As a medical researcher, I want to use languag...</td>\n",
              "      <td>As a medical researcher, I want to utilize lan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5991</th>\n",
              "      <td>Paraphrase the following user story: As a medi...</td>\n",
              "      <td>As a medical researcher, I want to use latent ...</td>\n",
              "      <td>As a medical researcher, I want to use latent ...</td>\n",
              "      <td>As a medical researcher, I want to use latent ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5996</th>\n",
              "      <td>Paraphrase the following user story: As a medi...</td>\n",
              "      <td>As a medical researcher, I desire leveraging t...</td>\n",
              "      <td>As a medical researcher, I want to use learnin...</td>\n",
              "      <td>As a medical researcher, I desire leveraging t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2887 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3014ad0c-449e-41f1-af0e-0a8f13926b45')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3014ad0c-449e-41f1-af0e-0a8f13926b45 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3014ad0c-449e-41f1-af0e-0a8f13926b45');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a671cfa8-7445-4e80-a79e-4dc3426adde3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a671cfa8-7445-4e80-a79e-4dc3426adde3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a671cfa8-7445-4e80-a79e-4dc3426adde3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_df",
              "summary": "{\n  \"name\": \"test_df\",\n  \"rows\": 2887,\n  \"fields\": [\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2887,\n        \"samples\": [\n          \"Paraphrase the following user story: As a network engineer, I want to use Rademacher complexity to evaluate the complexity and generalization performance of different machine learning models for network traffic prediction and control, in order to improve network efficiency and security..\\nBased on the following metrics: diff_total_characters: 1, diff_uppercase_characters: -1, diff_lowercase_characters: 3, diff_special_characters: 0, diff_numbers: 0, diff_blanks: -1, diff_number_of_words: -1, diff_average_length_of_words: 0.2154654654654653, diff_number_of_propositions: 0, diff_average_length_of_propositions: -1.0, diff_punctuation_characters: 0, diff_lowercase_words: 0, diff_uppercase_words: -1, diff_vocabulary_richness: -2, diff_number_of_urls: 0, diff_flesch_kincaid_grade_level: 0.8000000000000007, diff_flesch_reading_ease: -7.439999999999999, diff_dale_chall_readability: -1.6100000000000012, diff_automated_readability_index: 0.5, diff_coleman_liau_index: 1.2099999999999973, diff_gunning_fog: -2.3500000000000014, diff_smog_index: 0.0, diff_linsear_write_index: -0.5\",\n          \"Paraphrase the following user story: As an economist, I want to use terminology extraction techniques to identify and extract key economic terms from financial data and other sources, so that I can develop more accurate economic models and understand the factors that influence economic behavior..\\nBased on the following metrics: diff_total_characters: -2, diff_uppercase_characters: 0, diff_lowercase_characters: -2, diff_special_characters: 0, diff_numbers: 0, diff_blanks: 0, diff_number_of_words: 0, diff_average_length_of_words: -0.0499999999999998, diff_number_of_propositions: 0, diff_average_length_of_propositions: 0.0, diff_punctuation_characters: 0, diff_lowercase_words: 0, diff_uppercase_words: 0, diff_vocabulary_richness: 0, diff_number_of_urls: 0, diff_flesch_kincaid_grade_level: 1.099999999999998, diff_flesch_reading_ease: -8.46, diff_dale_chall_readability: -0.7899999999999991, diff_automated_readability_index: -0.1999999999999993, diff_coleman_liau_index: -0.2899999999999991, diff_gunning_fog: 1.0, diff_smog_index: 0.0, diff_linsear_write_index: 2.0\",\n          \"Paraphrase the following user story: As a librarian, I want to address overfitting in library user behavior prediction models, so that we can better understand and meet the needs of library users..\\nBased on the following metrics: diff_total_characters: -15, diff_uppercase_characters: 0, diff_lowercase_characters: -12, diff_special_characters: 0, diff_numbers: 0, diff_blanks: -3, diff_number_of_words: -3, diff_average_length_of_words: 0.0925925925925925, diff_number_of_propositions: 0, diff_average_length_of_propositions: -3.0, diff_punctuation_characters: 0, diff_lowercase_words: -3, diff_uppercase_words: 0, diff_vocabulary_richness: -2, diff_number_of_urls: 0, diff_flesch_kincaid_grade_level: -2.3999999999999986, diff_flesch_reading_ease: 11.5, diff_dale_chall_readability: -1.2599999999999998, diff_automated_readability_index: -1.0, diff_coleman_liau_index: 0.1600000000000001, diff_gunning_fog: -3.27, diff_smog_index: 0.0, diff_linsear_write_index: -3.5\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2887,\n        \"samples\": [\n          \"As a network engineer, I want to utilize Rademacher complexity to assess the intricacy and overall performance of various machine learning models for predicting and controlling network traffic, so that I can optimize network efficiency and security.\",\n          \"As an economist, I want to utilize terminology extraction techniques to identify and extract key economic terms from financial data and other sources, so that I can create more accurate economic models and comprehend the variables that impact economic behavior.\",\n          \"As a librarian, I want to mitigate overfitting in predictive models of library user behavior, so that we can more accurately understand and cater to the needs of our patrons.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"User Story\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2883,\n        \"samples\": [\n          \"As a network engineer, I want to use Rademacher complexity to evaluate the complexity and generalization performance of different machine learning models for network traffic prediction and control, in order to improve network efficiency and security.\",\n          \"As an endocrinologist, I want to use machine learning algorithms to analyze imbalanced datasets of patient data, including hormone levels and medical history, in order to identify patterns and improve diagnosis and treatment plans.\",\n          \"As a librarian, I want to address overfitting in library user behavior prediction models, so that we can better understand and meet the needs of library users.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Paraphrased User Story\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2887,\n        \"samples\": [\n          \"As a network engineer, I want to utilize Rademacher complexity to assess the intricacy and overall performance of various machine learning models for predicting and controlling network traffic, so that I can optimize network efficiency and security.\",\n          \"As an economist, I want to utilize terminology extraction techniques to identify and extract key economic terms from financial data and other sources, so that I can create more accurate economic models and comprehend the variables that impact economic behavior.\",\n          \"As a librarian, I want to mitigate overfitting in predictive models of library user behavior, so that we can more accurately understand and cater to the needs of our patrons.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = test_df.copy()\n",
        "df['prompt'][14]"
      ],
      "metadata": {
        "id": "Q_53yWo9z6oA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "outputId": "559a9716-39eb-4115-9d1e-6f5b1abc75c9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "14",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 14",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-c0228722a216>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prompt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1090\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 14"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cut_text(x):\n",
        "  prompt = '<s>[INST]' + x + '[/INST]'\n",
        "  num_new_tokens = 100  # change to the number of new tokens you want to generate\n",
        "\n",
        "  # Count the number of tokens in the prompt\n",
        "  num_prompt_tokens = len(tokenizer(prompt)['input_ids'])\n",
        "\n",
        "  # Calculate the maximum length for the generation\n",
        "  max_length = num_prompt_tokens + num_new_tokens\n",
        "\n",
        "  gen = pipeline('text-generation', model=model, tokenizer=tokenizer, max_length=max_length)\n",
        "  result = gen(prompt)\n",
        "  print(result[0]['generated_text'].replace(prompt, ''))\n",
        "  return result[0]['generated_text'].replace(prompt, '')\n",
        "\n",
        "\n",
        "df['llm_output'] = df['prompt'].apply(cut_text)\n",
        "df"
      ],
      "metadata": {
        "id": "1zXV0i-1Kq5L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76437146-c514-49b6-dc3b-7d4f968847f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " As a molecular biologist, I aim to leverage action model learning to predict the structure of complex biomolecules and design novel drugs with enhanced specificity and efficacy. This will enable the development of innovative treatments for diseases such as cancer and Alzheimer's.</s>\n",
            " As a bioinformatics researcher, I aim to utilize active learning settings to optimize the selection of training data for machine learning models that predict protein-protein interactions, thereby enhancing our understanding of biological pathways and facilitating drug discovery.</s>\n",
            " As a genomics researcher, I want to utilize the AdaBoost algorithm to identify genetic variations associated with complex diseases such as diabetes and heart disease, in order to enhance our understanding of the genetic basis of these diseases and develop personalized treatments.</s>\n",
            " A researcher in bioinformatics is utilizing an Adaline model to categorize diverse genetic sequences based on their underlying structures. By training the machine learning algorithm on vast sets of genomic data, the researcher hopes to uncover novel patterns and relationships between different genetic markers and their associated traits.</s>\n",
            " As a cognitive neuroscientist, I aim to leverage adaptive resonance theory to investigate how the brain processes and integrates information from multiple sensory modalities, in order to gain a deeper understanding of perception and develop novel therapies for sensory disorders such as blindness and deafness.</s>\n",
            " As a neuroscientist, I aim to leverage artificial neural networks to model the behavior of diverse brain regions and investigate how they communicate and interact with each other.</s>\n",
            " As a cognitive psychologist, I aim to utilize attention mechanisms to investigate how the brain selectively processes and prioritizes sensory information, in order to gain a deeper understanding of cognitive processing and develop novel therapies for attentional disorders such as ADHD.</s>\n",
            " A team of bioinformaticians is utilizing autoencoders to compress massive sets of genomic data into more compact representations, enabling more efficient analysis and processing of the information.</s>\n",
            " A team of researchers is utilizing automated summarization to extract crucial information from scientific articles and reports, enabling more efficient review and analysis of the literature.</s>\n",
            " As a bioinformatics analyst, I want to leverage bagging to enhance the accuracy of my predictive model for identifying genetic variants associated with drug response, to facilitate precision medicine and improve patient outcomes.</s>\n",
            "\n",
            "Based on the following metrics:\n",
            "\n",
            "* diff_total_characters: -11\n",
            "* diff_uppercase_characters: 0\n",
            "* diff_lowercase_characters: -9\n",
            "* diff_special\n",
            " As a computational biologist, I want to leverage Bayesian learning techniques to model the behavior of various biological systems and investigate how they respond to different stimuli and environmental factors.</s>\n",
            " As a computational biologist, I aim to leverage Bayesian neural networks to model complex biological systems and predict their behavior under diverse conditions, thereby gaining a deeper understanding of the underlying mechanisms that govern cellular processes.</s>\n",
            " As a bioinformatics researcher, I aim to utilize bi-directional long short-term memory networks to analyze vast sets of genomic data and uncover patterns of gene expression over time, thereby gaining a deeper understanding of the regulatory mechanisms that control cell function.</s>\n",
            " As a bioinformatics researcher, I aim to leverage the power of bidirectional long short-term memory (BiLSTM) networks to accurately predict protein structures based on their amino acid sequences. By training the BiLSTM network on a vast dataset of protein sequences and their corresponding structures, I can harness the network's ability to capture both forward and backward context, leading to more precise predictions about the 3D structure of proteins. This will\n",
            " As a computational biologist, I aim to leverage boosting techniques to forecast protein-protein interactions and identify novel drug targets, ultimately leading to the development of novel treatments for diseases such as cancer and Alzheimer's.</s>\n",
            " As a genomics researcher, I want to leverage bootstrap aggregating to enhance the accuracy of my predictive model for identifying genetic variants associated with disease, to facilitate precision medicine and improve patient outcomes.</s>\n",
            "\n",
            "Based on the following metrics:\n",
            "\n",
            "* diff_total_characters: -17\n",
            "* diff_uppercase_characters: 0\n",
            "* diff_lowercase_characters: -15\n",
            "* diff_special_\n",
            " As a bioinformatics researcher, I aim to utilize diverse classification algorithms to analyze vast genomic datasets and identify the genes and proteins most closely associated with specific diseases. By doing so, I can create personalized treatments and interventions.</s>\n",
            " As a computational biologist, I aim to utilize classification and regression trees to analyze vast amounts of genomic data and identify the genes and proteins most closely associated with specific diseases. By doing so, I can create targeted treatments and interventions, leading to improved patient outcomes.</s>\n",
            " As a bioinformatics researcher, I aim to evaluate various classification methods to identify the most accurate and reliable approach for predicting the presence or absence of specific genetic mutations associated with different diseases.</s>\n",
            " As a biologist, I aim to utilize a classifier chain to examine complex genetic datasets and identify the interrelationships between diverse genes and proteins, so that I can better comprehend the underlying biological processes.</s>\n",
            " As a bioinformatics researcher, I aim to utilize convolutional neural networks to analyze vast collections of imaging data and identify patterns of cell behavior that are linked to specific biological processes. By doing so, I hope to develop innovative diagnostic and therapeutic strategies for disease treatment.</s>\n",
            " As a bioinformatics researcher, I aim to leverage co-training techniques to enhance the accuracy and reliability of machine learning models in predicting the presence or absence of specific genetic mutations associated with various diseases.</s>\n",
            " As a neuroscientist, I aim to leverage competitive learning to investigate how neurons in the brain compete to process sensory information and acquire new skills, in order to better comprehend brain plasticity and create novel therapies for neurological disorders.</s>\n",
            " As a bioinformatics analyst, I want to leverage concept drift detection algorithms to monitor changes in bacterial communities over time, in order to investigate the impact of environmental factors such as pollution and climate change on microbial ecosystems.</s>\n",
            " A team of bioinformaticians is utilizing a conditional random field model to identify potential protein-protein interactions from vast amounts of genomic data. By incorporating contextual information and dependencies between different features, the team is able to more accurately predict protein interactions and gain insights into complex biological systems.</s>\n",
            " As a bioinformatician, I want to use consensus clustering to identify different subtypes of cancer based on their gene expression patterns, so that I can improve diagnosis and treatment options for patients.</s> As a bioinformatician, I aim to utilize consensus clustering to categorize various subtypes of cancer based on their gene expression patterns, thereby enhancing diagnosis and treatment alternatives for patients.</s> As a bioinformatician, I want\n",
            " As a clinical researcher, I aim to create a conversational AI using machine learning to interact with patients and collect data on their health status, lifestyle, and environmental factors to identify potential risk factors for diseases.</s>\n",
            " As a biologist, I aim to leverage conversational understanding techniques to create intelligent assistants that can respond to complex inquiries regarding biological systems and processes, such as the impact of gene expression on cellular functions.</s>\n",
            " As a biotechnology researcher, I aim to leverage the power of convolutional neural networks (CNNs) to predict the structure and function of various proteins based on their amino acid sequences. By doing so, I hope to identify potential drug development targets and other therapeutic interventions.</s>\n",
            " As a bioinformatics specialist, I want to leverage cross-language information retrieval techniques to extract relevant information from scientific literature written in diverse languages and construct comprehensive knowledge repositories for global biomedical research.</s>\n",
            " As a bioinformatician, I aim to enhance my genomic datasets through data augmentation techniques, which will improve the accuracy of my analyses and lead to the identification of new targets for drug development and other therapeutic interventions.</s>\n",
            " As a biologist, I aim to utilize data mining techniques to analyze vast datasets of gene expression data, thereby uncovering patterns and connections between genes and biological processes.</s>\n",
            " As a computational biologist, I want to leverage deep autoencoders to compactly represent large sets of genomic data, enabling me to uncover hidden patterns and relationships that would be challenging to detect through other methods.</s>\n",
            " As a biotechnology researcher, I aim to leverage deep learning techniques to analyze vast amounts of genomic data, uncovering the underlying biological pathways and mechanisms that drive cell function. This will enable me to identify potential drug development targets and other therapeutic interventions.</s>\n",
            " As a computational biologist, I aim to utilize dimensionality reduction techniques to identify the most critical features in vast sets of genomic data, thereby enabling me to more easily detect patterns and connections that may be crucial for comprehending biological function.</s>\n",
            " As a bioinformatics specialist, I aim to leverage discourse relation analysis to comprehend the flow of information in scientific articles and identify the most relevant information for addressing specific biological questions.</s>\n",
            " As a bioinformatician, I aim to utilize document clustering to group scientific articles based on similar topics and identify novel research directions and opportunities.</s>\n",
            " As a computational biologist, I aim to leverage document embedding techniques to represent scientific articles in a high-dimensional space. By doing so, I can perform information retrieval and recommendation tasks based on the semantic similarity between articles.</s>\n",
            " As a bioinformatics researcher, I aim to utilize embedding techniques to represent biological molecules and genomic data as continuous vectors, enabling me to leverage machine learning methods for analyzing and categorizing these data.</s>\n",
            " As a machine learning engineer working in drug discovery, I want to leverage empirical risk minimization to optimize the design of high-throughput drug screening assays, so that I can more efficiently identify potential drug candidates for further testing.</s>\n",
            " As a computational biologist, I aim to utilize encoder-decoder models to identify the regulatory elements that control gene expression, thereby enhancing my comprehension of the complex interactions within living systems.</s>\n",
            " As a bioinformatics researcher, I want to utilize entity extraction to automatically identify crucial terms in scientific literature, so that I can quickly and accurately locate relevant information for my analysis.</s>\n",
            " As an evolutionary biologist, I aim to leverage evolutionary learning algorithms to simulate the process of natural selection and comprehend how genetic variation and environmental factors contribute to the evolution of diverse species.</s>\n",
            " As a computational biologist, I want to utilize explicit semantic analysis to automatically identify and compare the meanings of various biological terms, so that I can better comprehend the relationships between different concepts.</s>\n",
            " As a computational biologist, I aim to leverage factorization techniques to uncover the underlying latent variables that contribute to complex biological processes. By doing so, I hope to gain a deeper understanding of the interplay between different genes and proteins.</s>\n",
            " As a biologist, I want to leverage fake news detection techniques to identify and filter out unreliable or misleading scientific information on social media, so that I can stay informed about the latest and most accurate research in my field.</s>\n",
            " As a machine learning engineer working in genomics, I want to utilize feature selection techniques to identify the most critical genetic features, so that I can create more accurate and predictive machine learning models.</s>\n",
            " As a biologist studying the impact of environmental factors on plant growth, I want to use feature sets to identify the key features that influence plant growth and development, so that I can better understand how to optimize plant growth in different conditions.</s> As a biologist studying the impact of environmental factors on plant growth, I want to use feature sets to identify the key features that influence plant growth and development, so that I can better understand how to optimize plant growth in different conditions.</s> As a bi\n",
            " As a bioinformatician, I aim to utilize generative adversarial networks to generate synthetic genomic data that can be employed to test and validate machine learning models, thereby enhancing the accuracy and robustness of my analyses.</s>\n",
            " As a computational biologist, I aim to leverage generative models to simulate various biological processes and test different hypotheses regarding the underlying mechanisms, allowing me to better comprehend the complex interactions that occur within living systems.</s>\n",
            " As a biologist, I aim to leverage GloVe to better comprehend the interrelationships between diverse biological terms and concepts, thereby enabling me to more accurately analyze and interpret my data.</s>\n",
            " As a machine learning engineer working in drug discovery, I want to leverage gradient boosting algorithms to optimize the design of drug molecules and predict their biological activity, so that I can more efficiently identify potential drug candidates for further testing.</s>\n",
            "\n",
            "Based on the following metrics:\n",
            "\n",
            "* diff_total_characters: -105\n",
            "* diff_uppercase_characters: 0\n",
            "* diff_lowercase_characters: -91\n",
            "* diff\n",
            " As a computational biologist, I aim to leverage grammar induction techniques to automatically identify the grammatical structure of biological language, such as gene sequences, in order to better comprehend and analyze the language.</s>\n",
            " As a bioinformatics researcher, I want to utilize graph mining techniques to automatically identify patterns and connections within vast biological datasets, such as gene expression data, so that I can more efficiently and accurately analyze the data.</s>\n",
            " As a computational biologist, I aim to utilize hidden Markov models to analyze vast sets of genomic data and uncover patterns of gene expression and other biological processes. By gaining a deeper understanding of these underlying mechanisms, I can improve my comprehension of cellular function.</s>\n",
            " A bioinformatics team is utilizing hierarchical clustering to analyze a vast dataset of gene expression profiles. The machine learning algorithms are trained to group genes with comparable expression patterns into clusters, enabling the team to identify crucial regulatory pathways and potential therapeutic targets.</s>\n",
            " As a neuroscientist, I aim to leverage hierarchical reinforcement learning to investigate how animals master navigating complex environments, such as mazes and forests, by analyzing neural activity within the brain.</s>\n",
            " A neuroscientist is utilizing a Hopfield network to model the interactions between neurons in the brain. The machine learning algorithms are trained to recognize patterns in the firing of neurons, allowing the researcher to better comprehend the neural basis of behavior.</s>\n",
            " As a researcher in the field of biotechnology, I want to leverage hybrid machine translation to automatically translate scientific articles from diverse languages, enabling me to better comprehend and collaborate with colleagues worldwide.</s>\n",
            " As a machine learning specialist, I aim to utilize the id3 algorithm to create decision trees that accurately forecast the outcomes of diverse experiments in the biological field. This will enable me to gain a deeper comprehension of the underlying mechanisms and relationships between various variables.</s>\n",
            " As a clinical researcher, I aim to leverage techniques for managing imbalanced datasets to develop predictive models for rare diseases, such as cystic fibrosis and Huntington's disease, and facilitate early diagnosis and treatment through improved model accuracy.</s>\n",
            " A team of bioinformatics researchers is utilizing inductive transfer techniques to enhance the accuracy of gene expression analysis in novel organisms. By leveraging knowledge and features acquired from previous investigations, the group can more promptly and precisely identify differentially expressed genes and gain insights into the genetic basis of complex traits.</s>\n",
            " As a computational biologist, I aim to leverage instance-based learning to identify the most relevant genetic markers for a particular disease, so that I can create more effective diagnostic tests and treatment options.</s>\n",
            " As a bioinformatics analyst, I want to leverage junction tree algorithms to model the complex interplay between genetic variations and disease manifestations, in order to identify potential therapeutic targets for challenging diseases such as cancer and diabetes.</s>\n",
            " As a bioinformatics researcher, I want to utilize keyphrase extraction to automatically identify the most crucial concepts and terms within vast sets of genomic data, so that I can promptly gain insights into the underlying biological processes.</s>\n",
            " As a microbiologist, I want to utilize keyword spotting techniques to automatically identify and categorize various strains of bacteria based on their genetic profiles, so that I can quickly recognize potential pathogens and develop effective treatments.</s>\n",
            " As a molecular biologist, I want to utilize Kleene star operations to analyze vast sets of genetic sequences and identify patterns of gene expression, so that I can better comprehend the complex regulatory mechanisms that control cell function.</s>\n",
            " A team of ecologists is utilizing a Kohonen neural network to analyze patterns in animal behavior. The machine learning algorithms are trained to identify groups of animals with similar behavior patterns, allowing the team to better comprehend the social structure of various animal populations.</s>\n",
            " As a computational linguist, I want to leverage language identification algorithms to automatically categorize scientific articles and other texts into their respective languages, so that I can create more accurate training data for my natural language processing models.</s>\n",
            " As a biologist, I want to leverage lazy learning algorithms to quickly categorize diverse species of animals based on their genetic profiles, so that I can more efficiently study their behaviors and ecological interactions in their natural habitats.</s>\n",
            " As a systems biologist, I aim to utilize learning automata to model the regulatory networks that control gene expression in cells, comprehending how cells respond to environmental stimuli and adapt to changing conditions.</s>\n",
            " As a computational biologist, I aim to utilize probabilistic graphical models to infer the regulatory network that controls gene expression within cells, thereby gaining a deeper understanding of the molecular mechanisms underlying diseases such as cancer and diabetes.</s>\n",
            " As a medical image analyst, I aim to leverage deep learning techniques to uncover latent representations of medical images, enabling more precise and automated diagnosis and prognosis of diseases such as lung cancer and Alzheimer's disease.</s>\n",
            " As a bioengineering researcher, I aim to leverage machine learning techniques to predict the effectiveness of various drug compounds on specific biological targets, thereby developing more targeted and effective treatments for diseases.</s>\n",
            " As a bioinformatics researcher, I aim to leverage machine learning algorithms to identify the most critical genes and proteins involved in specific biological pathways, thereby enhancing my comprehension of the underlying mechanisms of disease and developing more effective treatments.</s>\n",
            " A bioinformatics team is leveraging machine learning techniques to improve the accuracy of their gene expression analysis by adapting to changes in experimental conditions that may impact gene expression levels. The algorithms are trained to account for these variations, enabling the team to better identify meaningful patterns in their data.</s>\n",
            " As a computational biologist, I want to leverage learning vector quantization to automatically categorize various cell types based on their morphological features, so that I can gain a deeper understanding of the underlying mechanisms of disease and develop more effective treatments.</s>\n",
            " A team of biologists is utilizing a machine learning approach to analyze and interpret complex imaging data from biological samples. By training a deep neural network on labeled data, the group can automatically identify and categorize different features within the images and gain insights into the underlying biological processes.</s>\n",
            " As a patent lawyer specializing in biotechnology, I want to leverage legal information retrieval techniques to quickly and efficiently search and retrieve relevant patent documents, so that I can effectively represent my clients in legal proceedings.</s>\n",
            " As a biostatistician, I aim to utilize linear classifiers to identify the most critical predictors of disease onset and progression, so I can create more accurate risk prediction models for patients.</s>\n",
            " As a computational biologist, I aim to leverage linear separability techniques to identify common patterns of gene expression across diverse types of cancer. This will enable me to create more effective treatments and enhance patient outcomes.</s>\n",
            " A team of biologists leverages machine augmented intelligence to enhance their ability to analyze and interpret complex biological data. By combining human and machine intelligence, the team can identify patterns and relationships in the data more quickly and accurately, gaining deeper insights into biological systems.</s>\n",
            " As a computational biologist, I aim to utilize the Matthews correlation coefficient to evaluate the accuracy of my machine learning model in predicting the 3D structure of proteins from their amino acid sequence, which can facilitate drug discovery and design.</s>\n",
            " A bioinformatics team is utilizing medoids to select representative samples from a vast dataset of genomic data. The machine learning algorithms are trained to identify samples that best embody the underlying patterns in the data, allowing the team to more efficiently analyze and interpret their findings.</s>\n",
            " As a biologist, I aim to create a machine learning model that can detect specific gene and protein mentions in research articles, enabling me to quickly and easily locate relevant information for my research.</s>\n",
            " A team of biostatisticians is utilizing mixture models to analyze a vast dataset of patient health records. The machine learning algorithms are trained to identify distinct subpopulations of patients with similar health profiles, enabling the team to create more personalized treatments for various patient groups.</s>\n",
            " As a bioinformatics researcher, I aim to utilize multi-class classification algorithms to categorize various types of cells based on their gene expression profiles, allowing me to gain a deeper understanding of the underlying mechanisms of disease and develop more effective treatments.</s>\n",
            " As a bioinformatician, I aim to create a machine learning model for multimodal translation of complex biomedical information, enabling me to effectively communicate scientific findings and medical information to a broader audience.</s>\n",
            " As a computational biologist, I want to utilize multiple instance learning to automatically recognize various types of cells and tissues based on their visual features, so that I can better comprehend their biological functions and develop more effective treatments.</s>\n",
            " As a bioinformatics researcher, I want to leverage multiple kernel learning to integrate data from various sources and identify the most critical features for predicting cancer treatment efficacy, so that I can create personalized treatment plans for patients.</s>\n",
            " As a microbiologist, I want to leverage multiple-instance learning to identify potential antibiotic-resistant bacteria based on their genetic profiles, so that I can create novel strategies for controlling the spread of antibiotic resistance in hospitals and other healthcare settings.</s>\n",
            " As a computational linguist in the field of genetics, I aim to create a machine learning model to recognize and extract multiword expressions that describe complex genetic interactions, allowing me to better comprehend the underlying mechanisms of gene expression and regulation.</s>\n",
            " As a bioinformatician, I aim to utilize n-grams to investigate and categorize vast datasets of genomic sequences, so that I can identify patterns and connections between diverse genes and their functions.</s>\n",
            " As a biostatistician, I aim to utilize naive Bayes classifiers to forecast the likelihood of diverse disease outcomes based on patient traits and medical history, so that I can create more precise risk prediction models for clinical use.</s>\n",
            " As a genomics researcher, I want to utilize natural language generation to produce clear and concise summaries of my findings, so that my work can be more accessible to a broader audience.</s>\n",
            " A research team is developing a natural language interface for a new gene editing technology using machine learning techniques to train the interface to understand and respond to natural language queries about gene editing, making it easier for biologists to use the technology.</s> A research team is creating a natural language interface for a new gene editing technology using machine learning to train the interface to understand and respond to natural language queries about gene editing, making it simpler for biologists to utilize the technology.</s> A research group\n",
            " A team of biologists is leveraging natural language semantics to analyze a vast dataset of scientific papers and identify crucial concepts and connections between them. The machine learning algorithms are trained to recognize the semantic relationships between words and phrases, enabling the team to quickly uncover significant insights and trends.</s>\n",
            " A biotech company is leveraging natural language understanding to enhance their customer support system. Machine learning algorithms are trained to comprehend and respond to customer inquiries regarding the company's products, making it simpler for customers to obtain the information they need.</s>\n",
            " As a biotech engineer, I aim to create customized neural network hardware that can swiftly process vast amounts of genomic data in real-time, enabling me to develop innovative diagnostic tools and treatments for genetic diseases.</s>\n",
            " As a neuroscientist, I aim to leverage neuromorphic engineering to create more accurate and efficient models of neural systems, enabling a deeper comprehension of brain function and the development of more effective treatments for neurological disorders.</s>\n",
            " A pharmaceutical company leverages news analytics to monitor advancements in oncology by training machine learning algorithms to analyze news articles and social media posts related to cancer research. This enables the company to stay informed about the latest developments in the field.</s>\n",
            " A team of bioinformaticians is leveraging natural language processing to analyze the scientific literature on a particular gene. The machine learning algorithms are trained to identify crucial concepts and relationships between them, enabling the team to gain a deeper understanding of the gene's function and potential applications.</s>\n",
            " As a pharmacologist, I aim to leverage one-class classification techniques to predict the toxicity of newly developed drug candidates based on their chemical structure and similarity to known toxic compounds. By doing so, I can minimize the risk of adverse effects and enhance drug safety.</s>\n",
            " As a medical data analyst, I want to leverage online machine learning algorithms to predict patient outcomes and adjust treatment plans in real-time, using continuously updated patient data and feedback from clinicians.</s>\n",
            " A team of bioinformaticians is utilizing ontology learning to create a standardized vocabulary for describing genetic variants. The machine learning algorithms are trained to identify key features of the variants and categorize them based on their functional impact, making it simpler for researchers to share and compare genetic data.</s>\n",
            " A scientist wants to automatically identify and extract gene and protein names from scientific papers using open information extraction techniques.</s>\n",
            " As a bioimage analyst, I aim to optimize the design and training of deep neural networks to accurately segment cell nuclei from fluorescence microscopy images, leading to a deeper understanding of cellular processes and disease mechanisms.</s>\n",
            " As a bioinformatics software developer, I aim to prevent overfitting my machine learning model to genomic data by utilizing regularization techniques and cross-validation to enhance the accuracy of my predictive models for genomic data analysis.</s>\n",
            " As a bioinformatician, I want to use principal component analysis to simplify and summarize large datasets of genomic information, and identify the most significant features that are linked to various diseases and biological processes.</s>\n",
            " As a bioinformatician, I aim to utilize perceptron algorithms to categorize diverse types of genetic mutations based on their associated clinical outcomes using perceptron algorithms.</s>\n",
            " A bioinformatics researcher is interested in identifying common biological pathways across different species and uses phrase embeddings to represent and compare the pathways.</s> A bioinformatics researcher is fascinated by identifying similar biological pathways across various species and utilizes phrase embeddings to represent and contrast these pathways.</s> A bioinformatics researcher aims to identify common biological pathways across different species and uses phrase embeddings to\n",
            " As a computational biologist, I aim to utilize policy iteration algorithms to optimize drug dosing and scheduling in cancer chemotherapy, maximizing therapeutic efficacy while minimizing toxicity, through the use of policy iteration algorithms.</s>\n",
            " As a computational biologist, I aim to utilize probabilistic inference to analyze vast sets of genomic data and identify the most likely biological pathways and interactions between genes and proteins, so that I can gain a deeper understanding of the underlying mechanisms that regulate cell function.</s>\n",
            " As a bioinformatician, I aim to utilize probabilistic neural networks to forecast the functions of diverse genes based on their DNA sequences, thereby enabling the identification of potential drug targets and other therapeutic interventions.</s>\n",
            " A research team aims to create a tool that can answer natural language questions about gene function by leveraging question answering techniques to automatically retrieve relevant information from scientific publications.</s>\n",
            " As a biotechnology researcher, I aim to utilize radial basis function networks to categorize diverse types of cancer cells based on their gene expression profiles, so that I can create more effective treatments and therapies.</s>\n",
            " As a genetic counselor, I want to leverage recommendation systems to identify potential genetic risks for patients based on their family history and other factors, so that we can create personalized prevention and treatment plans.</s>\n",
            " As a bioinformatics researcher, I aim to leverage recommender engines to identify potential drug targets based on their molecular structure and interactions, ultimately leading to the development of more effective drugs with fewer side effects.</s>\n",
            " As a healthcare provider, I want to leverage recommender systems to identify potential treatment options for patients based on their medical history and other factors, so that we can create personalized treatment plans tailored to each individual's unique needs, leading to optimal outcomes.</s>\n",
            " As a biostatistician, I aim to enhance the accuracy of my predictive model for forecasting the outcome of clinical trials by leveraging regularization techniques, ultimately facilitating drug development and approval processes.</s>\n",
            " As a bioinformatics researcher, I aim to utilize representation learning techniques to automatically extract meaningful features and patterns from vast sets of genomic data, thereby enhancing my comprehension of the complex relationships between diverse genes and proteins.</s>\n",
            " As a biotechnology researcher, I aim to utilize restricted Boltzmann machines to analyze vast sets of protein interaction data and uncover the underlying biological pathways and mechanisms that regulate cell function.</s>\n",
            " As a robotics engineer, I aim to leverage robot learning algorithms to create more intelligent and efficient robots that can support tasks such as surgery and patient care, ultimately enhancing the quality of healthcare delivery.</s>\n",
            " As a bioinformatics researcher, I aim to utilize self-attention mechanisms to automatically extract meaningful features and patterns from vast sets of genomic data, thereby enhancing my comprehension of the complex relationships between diverse genes and proteins.</s>\n",
            " A computational biologist is analyzing a large dataset of protein-protein interactions and uses semantic dependency parsing to identify the relationships and dependencies between the proteins.</s>\n",
            " A bioinformatics researcher is developing a system to integrate and analyze large amounts of biological data using a semantic reasoner to infer new knowledge from the data.</s>\n",
            " A team of computational linguists is leveraging semantic role labeling (SRL) to analyze a vast corpus of biomedical text. By training machine learning algorithms to identify the roles played by various entities in the text, the team can gain a deeper understanding of the relationships between genes, proteins, and other biological entities.</s>\n",
            " A team of biologists is utilizing semantic similarity to identify genes and proteins that are functionally related. The machine learning algorithms are trained to compare the semantic features of different entities, enabling the team to uncover novel connections between various biological systems.</s>\n",
            " A team of computational biologists is utilizing semantic web data to create a comprehensive ontology of biological concepts and relationships. Machine learning algorithms are trained to analyze vast amounts of structured data, enabling the team to generate an accurate and up-to-date representation of the field.</s>\n",
            " As a bioinformatics researcher, I aim to leverage semi-supervised learning techniques to analyze vast amounts of genomic data and identify potential drug targets, even when limited labeled data is available.</s>\n",
            " As a bioinformatician, I want to leverage similarity learning algorithms to identify similarities and differences between various bacterial strains based on their genomic profiles, so that I can gain a deeper understanding of bacterial pathogenesis and develop more effective treatments.</s>\n",
            " A team of bioinformaticians leverages speech-to-text technology to analyze patient interviews and other clinical data. Machine learning algorithms are trained to transcribe speech and identify key concepts and themes, enabling healthcare providers to quickly and accurately identify potential health concerns.</s>\n",
            " A neuroscience lab is developing spiking neural networks to model the activity of neurons in the brain and better understand the mechanisms of learning and memory.</s> A neuroscience lab is creating spiking neural networks to simulate the activity of neurons in the brain and gain insights into the processes of learning and memory.</s> A neuroscience lab is working on developing spiking neural networks to mimic the activity of neurons in the brain and better comprehend\n",
            " A team of researchers is developing a spoken dialogue system to enhance communication between individuals with disabilities and their caregivers. Machine learning algorithms are trained to recognize and interpret spoken language, enabling the system to provide appropriate responses and support as needed.</s>\n",
            " A bioinformatics company is leveraging statistical learning methods to analyze vast sets of genomic data, uncovering patterns and connections between diverse genes and proteins. This enables the development of innovative treatments for genetic disorders.</s>\n",
            " A group of computational linguists are utilizing statistical machine translation methods to automatically translate scientific papers and other technical documents from one language to another, with the goal of facilitating global scientific collaboration.</s>\n",
            " A team of computational linguists is utilizing stemming algorithms to analyze a vast corpus of scientific articles in the field of genetics. The machine learning models are trained to identify and group together various forms of the same word, allowing the researchers to more easily identify patterns and trends in the data.</s>\n",
            " A team of computational biologists are utilizing stochastic game theory to model the interactions between diverse cells in the immune system, with the ultimate goal of gaining a deeper understanding of the immune response's dynamics.</s>\n",
            " A group of bioinformatics researchers is utilizing string kernel algorithms to analyze vast sets of genomic data. The machine learning models are trained to identify patterns and similarities between diverse DNA sequences, enabling the researchers to better understand the interrelationships between different genes and genetic processes.</s>\n",
            " As a computational chemist, I aim to leverage the concept of structural risk minimization to create a machine learning model that accurately predicts the binding affinity of small molecules to protein targets, ultimately facilitating drug discovery and design.</s>\n",
            " As a bioinformatics researcher, I aim to utilize structured prediction algorithms to analyze vast sets of clinical data and identify potential risk factors for disease, ultimately leading to the development of more effective prevention and treatment strategies.</s>\n",
            " As a bioinformatics researcher, I aim to leverage supervised learning algorithms to predict the functions of diverse genes based on their DNA sequences, thereby enhancing my understanding of underlying biological processes and identifying potential drug targets.</s>\n",
            " As a bioinformatician, I aim to utilize support vector machines to analyze vast sets of genomic data and identify potential biomarkers for diverse diseases, so that I can create more targeted and effective treatments.</s>\n",
            " A team of researchers is utilizing symbolic learning to identify complex networks of gene regulation that control plant cell development, enabling the production of crops with improved yield and resistance to environmental stresses.</s>\n",
            " A team of computational linguists is utilizing syntactic pattern recognition techniques to automatically categorize and classify various types of scientific papers and technical documents, with the ultimate goal of enhancing information retrieval and knowledge discovery.</s>\n",
            " As a computational biologist, I want to leverage TensorFlow to create a sophisticated neural network that accurately predicts the function of unidentified proteins based on their amino acid sequence, enabling precise functional annotation and drug discovery.</s>\n",
            " A team of bioinformatics researchers is utilizing text categorization techniques to analyze a vast collection of scientific articles in the field of genetics. The machine learning algorithms are trained to categorize articles based on their content, allowing the researchers to more easily identify relevant articles for their research.</s>\n",
            " A genetics company leverages text summarization to automatically generate executive summaries of scientific reports. The machine learning models are trained to identify crucial concepts and themes, enabling the team to quickly comprehend the findings of a study.</s>\n",
            " A team of biologists leverages textual entailment to automatically assess whether a scientific article supports or contradicts a particular hypothesis. The machine learning models are trained to identify crucial concepts and relationships, enabling the team to quickly determine the validity of a hypothesis.</s>\n",
            " A computational biologist is utilizing tf-idf to identify the most crucial genes in a vast collection of genomic data. The machine learning algorithms are trained to recognize genes that are both highly expressed and distinctive to a particular cell type, allowing the researcher to better comprehend cell function.</s>\n",
            " A team is utilizing time-series classification to predict the onset of epileptic seizures based on patterns in brain activity, resulting in improved patient outcomes and quality of life.</s>\n",
            " A machine learning company is utilizing the TIMIT database to train their algorithms to accurately transcribe spoken words. The database contains diverse speech recordings from various backgrounds and accents, allowing the algorithms to perform well on different speech inputs.</s>\n",
            " A team of biologists is utilizing topic modeling to identify crucial research themes and trends within a vast collection of scientific articles. The machine learning algorithms are trained to detect patterns in the data, enabling the team to quickly identify emerging areas of research.</s>\n",
            " Researchers are utilizing transfer learning to predict the likelihood of a patient developing a specific type of cancer based on genomic data, enabling early diagnosis and personalized treatment plans.</s>\n",
            " As a plant biologist, I aim to leverage tree algorithms to analyze vast sets of plant genomic data, identifying genetic markers linked to crucial traits such as disease resistance. This will enable me to develop more effective breeding strategies for crop improvement.</s>\n",
            " A team of computational biologists are utilizing unsupervised learning techniques to analyze vast biological networks and uncover patterns and connections between diverse genes and proteins, with the ultimate goal of gaining a deeper understanding of the underlying mechanisms of disease.</s>\n",
            " A bioinformatics company is leveraging visual question answering to automatically respond to questions about biological images. The machine learning models are trained to recognize various biological structures and relationships between them, enabling the system to provide accurate answers to a wide range of queries.</s>\n",
            " As a researcher in genetics, I want to utilize voice recognition software to transcribe interviews with patients and families affected by rare genetic disorders, so that I can gain a deeper understanding of their experiences and develop more effective treatments.</s>\n",
            " As a molecular biologist, I aim to leverage word similarity measures to identify relationships between diverse genes and proteins based on their shared functions and interactions, allowing me to better comprehend complex biological systems.</s>\n",
            " As a computational biologist, I aim to utilize word2vec to analyze vast sets of genomic data and identify recurring patterns of gene expression, so that I can better comprehend the underlying regulatory mechanisms that control cell function.</s>\n",
            " As a cardiologist, I want to leverage action model learning to enhance my ability to predict the onset of heart disease in patients based on various risk factors, allowing me to intervene sooner and potentially save lives.</s>\n",
            " As a cardiologist, I want to leverage machine learning techniques to analyze and predict cardiovascular disease using activation functions that can accurately identify the risk factors and symptoms associated with heart disease.</s>\n",
            " As a cardiologist, I want to leverage active learning techniques to quickly and accurately identify and classify abnormal heart patterns in ECG recordings, allowing for faster and more accurate diagnoses.</s>\n",
            " As a cardiologist, I aim to leverage AdaBoost to predict the likelihood of heart disease and identify crucial factors that contribute to heart health, ultimately enhancing patient care.</s>\n",
            " As a cardiologist, I want to leverage adaptive resonance theory to analyze patterns in patient data and predict the likelihood of heart disease, so that I can provide more accurate diagnoses and treatment plans for my patients.</s>\n",
            " As a cardiologist, I aim to leverage artificial neural networks to analyze and predict heart disease risk and patient outcomes, thereby improving treatment and prevention strategies.</s>\n",
            " As a cardiologist, I want to leverage attention mechanisms in a machine learning model to uncover patterns and connections within patient data, including medical history, test results, and genetic information, so that we can enhance diagnosis and treatment of cardiovascular diseases.</s>\n",
            " As a cardiology clinic, we aim to leverage automated pattern recognition on cardiac signals to detect irregular heart rhythms, enabling us to provide accurate diagnoses and treatment recommendations to patients.</s>\n",
            " A cardiologist is utilizing machine learning to predict the likelihood of heart disease in patients based on various factors, such as age, gender, and lifestyle. They are training a neural network using backpropagation to enhance the accuracy of the risk prediction model.</s>\n",
            " A cardiologist is utilizing machine learning to categorize heart rate data based on the type of arrhythmia present. They are employing a bag of words approach to extract features from the heart rate data and train a classifier to identify the specific type of arrhythmia.</s>\n",
            " As a cardiologist, I aim to leverage Bayesian learning to analyze vast datasets of patient heart health data, enabling me to make more accurate predictions about patient outcomes and develop more effective treatments.</s>\n",
            " As a cardiologist, I aim to leverage Bayesian neural network models to analyze patient data, enabling me to make more accurate medical diagnoses and develop more effective treatment plans. This will lead to improved cardiovascular health for patients and reduced healthcare costs.</s>\n",
            " As a cardiologist, I aim to leverage the power of BILSTM models to analyze heart rate data and forecast the likelihood of heart disease. By doing so, I can provide timely interventions and preventive care to those at high risk, ultimately improving patient outcomes and quality of life.</s>\n",
            " As a cardiologist, I aim to utilize binary classification models to predict which patients are at high risk for heart disease or cardiac events, so that I can provide more targeted and effective preventative care.</s>\n",
            " As a cardiologist, I aim to leverage boosting techniques to forecast and analyze patient outcomes and treatment efficacy, thereby enabling me to provide more targeted and effective care to patients with heart disease.</s>\n",
            " As a cardiologist, I want to use canonical correlation analysis to identify the relationship between cardiovascular health and lifestyle factors, so that I can provide personalized recommendations to my patients based on their unique characteristics and habits.</s>\n",
            " As a cardiologist, I want to leverage CapsNet to classify heart sounds and detect abnormal patterns, enabling me to provide more accurate diagnoses and improve patient outcomes.</s>\n",
            " As a cardiologist, I want to use case-based reasoning to identify the most effective treatments for a specific heart condition, so that I can provide the best possible care for my patients.</s>\n",
            " As a cardiologist, I want to use CHAID to identify the factors that contribute to heart disease and cardiovascular health in a particular population, so that I can develop targeted interventions and improve patient outcomes.</s>\n",
            " As a cardiologist, I aim to utilize a chatbot to provide patient education and guidance on heart disease prevention and management, enhancing their understanding and empowering them to take control of their health.</s>\n",
            " As a cardiologist, I aim to utilize a classifier to categorize various types of heart disease, enabling me to create tailored treatment plans.</s>\n",
            " As a cardiologist, I want to use a classifier chain to predict various types of heart conditions by analyzing the interactions between multiple factors, such as patient history and lifestyle habits, so that I can create personalized treatment plans.</s>\n",
            " As a cardiologist, I aim to leverage co-training to identify potential risk factors and predict heart disease.</s>\n",
            " As a cardiologist, I aim to leverage competitive learning to predict heart disease and enhance patient outcomes.</s>\n",
            " As a cardiologist, I aim to leverage computational argumentation to evaluate and enhance the efficacy of diverse treatments for heart diseases.</s>\n",
            " As a cardiologist, I want to use concept drift detection in machine learning models to detect changes in patient health status and risk factors, so that I can adjust my treatment plans and interventions accordingly.</s> As a cardiologist, I aim to utilize concept drift detection in machine learning algorithms to identify shifts in patient health conditions and risk factors. This enables me to adapt my treatment plans and interventions to better address the evolving needs of my patients.</s>\n",
            " As a cardiologist, I want to use conceptual clustering to group patients based on their medical histories and risk factors, such as identifying clusters of patients with a high risk of heart disease or stroke, so that we can develop more targeted treatment plans.</s> As a cardiologist, I aim to utilize conceptual clustering to categorize patients according to their medical backgrounds and hazard factors, such as recognizing clusters of patients with a high risk of heart\n",
            " As a cardiologist, I want to leverage conditional GANs to generate synthetic medical images with various heart conditions and treatment responses, such as identifying clusters of images with high cardiovascular risk or treatment success. This will enable us to develop and evaluate treatment plans more effectively.</s>\n",
            " As a cardiologist, I want to leverage conditional random fields to forecast heart disease risk and treatment response based on medical and environmental variables, such as identifying clusters of patients with high cardiovascular disease risk or predicting treatment success rates, so that we can better develop and evaluate treatment plans.</s>\n",
            " As a cardiologist, I want to leverage consensus clustering in machine learning models to group patients with similar medical characteristics and outcomes, allowing me to better comprehend cardiovascular disease and create more effective treatment plans.</s>\n",
            " As a cardiologist, I want to use natural language processing techniques to analyze patient data, such as medical records and test results, to gain insights and make more informed decisions about patient care.</s>\n",
            " As a cardiologist, I want to leverage cost-sensitive learning to create models that can accurately identify and address potential biases in diagnosis and treatment for underrepresented groups, such as women or minorities.</s>\n",
            " As a cardiologist, I need to preprocess the ECG data to remove any noise and artifacts before diagnosing heart conditions.</s> As a cardiologist, I require preprocessing of ECG data to remove any noise and artifacts before diagnosing heart conditions.</s> As a cardiologist, I need to preprocess ECG data before diagnosing heart conditions to remove any noise and artifacts.</s> As a cardiologist, I require preprocessing of ECG\n",
            " As a cardiologist, I aim to create a decision tree model to diagnose heart disease based on medical test results and patient history using machine learning algorithms.</s>\n",
            " As a cardiologist, I aim to leverage a deep belief network to forecast the likelihood of heart disease based on medical data and patient history.</s>\n",
            " As a cardiologist, I want to utilize the delta rule to analyze patient data in order to enhance diagnosis and treatment of heart disease, thereby improving patient outcomes and quality of care.</s>\n",
            " As a cardiologist, I want to utilize a conversational system to engage with patients and provide personalized recommendations and guidance on heart health and disease management, so that I can improve patient outcomes and enhance the overall quality of care.</s>\n",
            " As a cardiology researcher, I aim to leverage discourse and dialogue analysis to gain insights into how patients communicate about their heart health and develop more effective communication strategies for promoting cardiovascular wellness.</s>\n",
            " As a cardiologist, I want to leverage document embedding to represent medical records as heart disease-specific vector representations, enabling me to more efficiently analyze patient data and develop targeted treatment plans.</s>\n",
            " As a cardiologist, I want to leverage domain adaptation techniques to adapt models trained on one patient population to another, enabling me to better diagnose and treat diverse patient populations.</s>\n",
            " As a cardiologist, I aim to leverage Elman networks to predict which patients are most susceptible to heart disease based on their medical history, lifestyle factors, and genetic information. Additionally, I seek to utilize Elman networks to model the progression of heart disease and forecast the effectiveness of diverse treatments.</s>\n",
            " As a cardiologist, I want to utilize an embedding approach to represent patient medical records and their clinical characteristics based on their medical history and laboratory test results, in order to predict the likelihood of developing heart disease and improve treatment outcomes.</s>\n",
            " As a cardiologist, I want to leverage ensemble learning techniques to combine multiple machine learning models that predict the likelihood of developing heart disease and cardiovascular events based on patient medical records and laboratory test results. By integrating these models, I can enhance prevention and treatment strategies, ultimately leading to better patient outcomes.</s>\n",
            " As a cardiologist, I want to leverage entity linking to connect cardiology-related entities such as heart conditions, treatments, and medications to relevant entries in cardiology databases, allowing me to gain a deeper understanding of cardiology trends and inform medical research and treatment decisions more effectively.</s>\n",
            " As a cardiologist, I aim to leverage evolutionary robotics to simulate blood flow and test innovative treatments for heart disease through virtual simulations, thereby improving patient outcomes and advancing medical research.</s>\n",
            " As a cardiologist, I aim to utilize factorization techniques to analyze patient data and identify crucial factors influencing heart disease outcomes and treatment effectiveness. By doing so, I can create more personalized treatment plans and provide better patient care.</s>\n",
            " As a cardiologist, I want to leverage fake news detection to identify and correct false information and misinformation about heart health and treatment, so that patients can be better informed and receive appropriate care.</s> As a cardiologist, I aim to utilize fake news detection to identify and correct false information and misinformation about heart health and treatment, ensuring that patients receive accurate and reliable information, leading to better informed decision-making and improved health outcomes.</s>\n",
            " As a cardiologist, I want to leverage the power of fastText to analyze medical records and uncover patterns in patient data, so that we can gain a deeper understanding of cardiovascular diseases and develop more effective treatments.</s>\n",
            " As a cardiologist, I want to leverage feature engineering techniques to extract meaningful features from medical records, such as patient demographics and medical history, so that we can better understand and diagnose cardiovascular diseases.</s>\n",
            " As a cardiologist, I want to utilize feature extraction techniques to identify and extract meaningful features from cardiac data, such as ECG signals and heart rate variability, so that we can better diagnose and treat heart conditions.</s>\n",
            " As a cardiologist, I want to utilize feature hashing to analyze patient data and identify factors that contribute to heart disease, so that I can better diagnose and treat patients.</s>\n",
            "\n",
            "Based on the following metrics:\n",
            "\n",
            "* diff_total_characters: -20\n",
            "* diff_uppercase_characters: 1\n",
            "* diff_lowercase_characters: -21\n",
            "* diff_special_characters: 0\n",
            "* diff\n",
            " As a cardiologist, I want to use feature selection to analyze patient data and identify the most important features related to heart disease, so that I can better diagnose and treat patients.</s> As a cardiologist, I aim to utilize feature selection to examine patient data and recognize the most critical features related to heart disease, allowing me to more accurately diagnose and treat patients.</s> As a cardiologist, I want to use feature selection to analyze patient data and identify the\n",
            " As a cardiologist, I want to utilize a feedforward neural network to predict cardiac risk factors and outcomes based on patient health data, so that I can better diagnose and treat patients with heart disease.</s>\n",
            "\n",
            "Based on the following metrics:\n",
            "\n",
            "* diff_total_characters: -42\n",
            "* diff_uppercase_characters: 0\n",
            "* diff_lowercase_characters: -38\n",
            "* diff_special_char\n",
            " As a cardiologist, I aim to utilize fully connected layers to forecast cardiac results based on extensive datasets of patient cardiac data, so that I can better diagnose and treat heart conditions.</s>\n",
            " As a cardiologist, I want to leverage fuzzy neural networks to forecast cardiovascular disease risk and outcomes based on extensive datasets of patient data, so that I can better diagnose and treat patients with heart disease.</s>\n",
            " As a cardiologist, I want to leverage machine learning techniques to evaluate the generalization error of my models in predicting patient outcomes following cardiac surgery, so that I can improve the accuracy of my predictions and better serve my patients.</s>\n",
            " As a cardiologist, I aim to leverage Generative Adversarial Networks (GANs) to create synthetic medical images of heart structures, enhancing our understanding of heart disease and improving our diagnostic and treatment capabilities.</s>\n",
            " As a cardiologist, I aim to leverage grammar induction techniques to analyze and comprehend the underlying rules and structures in cardiac data and medical literature. By doing so, I hope to gain a deeper understanding of cardiac diseases and develop more effective treatments and interventions.</s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_after_endtoken(x):\n",
        "    if '</s>' in x:\n",
        "        return x.split('</s>')[0]\n",
        "    return x\n",
        "\n",
        "df['llm_output'] = df['llm_output'].apply(remove_after_endtoken)\n"
      ],
      "metadata": {
        "id": "MpTZdAz1N02a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns=['prompt', 'response', 'llm_output2'])"
      ],
      "metadata": {
        "id": "WNX5wr8ojI_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = df.copy()"
      ],
      "metadata": {
        "id": "3iXKwQUUNyVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "52_D_NFmjgJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Reshape the DataFrame\n",
        "num_rows = df.shape[0]\n",
        "num_cols = df.shape[1]\n",
        "reshape_data = []\n",
        "\n",
        "for i in range(num_rows):\n",
        "    for j in range(num_cols):\n",
        "        reshape_data.append(df.iloc[i, j])\n",
        "\n",
        "# Create a new DataFrame with reshaped data\n",
        "reshaped_df = pd.DataFrame(columns=['reshaped_column'], data=reshape_data)\n",
        "\n",
        "def name_the_text(ind):\n",
        "  if ind % 3 == 0:\n",
        "    return 'Original'\n",
        "  elif ind % 3 == 1:\n",
        "    return 'Paraphrased'\n",
        "  return 'LLM'\n",
        "\n",
        "reshaped_df['origin'] = reshaped_df.index.map(name_the_text)\n",
        "reshaped_df"
      ],
      "metadata": {
        "id": "hLziYVufNCp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric_functions = [\n",
        "    total_characters,\n",
        "    uppercase_characters,\n",
        "    lowercase_characters,\n",
        "    special_characters,\n",
        "    numbers,\n",
        "    blanks,\n",
        "    number_of_words,\n",
        "    average_length_of_words,\n",
        "    number_of_propositions,\n",
        "    average_length_of_propositions,\n",
        "    punctuation_characters,\n",
        "    lowercase_words,\n",
        "    uppercase_words,\n",
        "    vocabulary_richness,\n",
        "    number_of_urls,\n",
        "    flesch_kincaid_grade_level,\n",
        "    flesch_reading_ease,\n",
        "    dale_chall_readability,\n",
        "    automated_readability_index,\n",
        "    coleman_liau_index,\n",
        "    gunning_fog,\n",
        "    smog_index,\n",
        "    linsear_write_index\n",
        "]"
      ],
      "metadata": {
        "id": "K0cYYPKbSqH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "0KFFAkynTGDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for func in metric_functions:\n",
        "    reshaped_df[func.__name__] = reshaped_df['reshaped_column'].apply(func)\n",
        "reshaped_df"
      ],
      "metadata": {
        "id": "kyH9d1XVSnqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reshaped_df.to_csv(\"gen_output_metrics.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "R5oDiMuER2KP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('all_versions.csv')"
      ],
      "metadata": {
        "id": "qJlrgaS5VQ4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G7qJsfhzOIZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(valid_dataset_mapped['text']).to_csv('instructions.csv')"
      ],
      "metadata": {
        "id": "FF80WXUOVrYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aAUG13xXVrSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_dataset_mapped[0]['prompt'].split(':')[1].split('.')[0]\n",
        "valid_dataset_mapped[0]['response']\n",
        "\n",
        "prompt = valid_dataset_mapped[0]['text'].split('[/INST]')[0] + '[/INST]'\n",
        "num_new_tokens = 100  # change to the number of new tokens you want to generate\n",
        "\n",
        "# Count the number of tokens in the prompt\n",
        "num_prompt_tokens = len(tokenizer(prompt)['input_ids'])\n",
        "\n",
        "# Calculate the maximum length for the generation\n",
        "max_length = num_prompt_tokens + num_new_tokens\n",
        "\n",
        "gen = pipeline('text-generation', model=model, tokenizer=tokenizer, max_length=max_length)\n",
        "result = gen(prompt)\n",
        "print(result[0]['generated_text'].replace(prompt, ''))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yapKlJa-XYi",
        "outputId": "41153423-d6ef-4834-8390-9256fca9fc7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A computational biologist is using backpropagation to train a machine learning algorithm to predict the likelihood of different genetic mutations leading to cancer by analyzing large sets of genomic data. The algorithm is trained to identify the underlying genetic factors that contribute to cancer development.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_dataset_mapped[0]['text'].split('[/INST]')[0] + '[/INST]'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "ZDDRXJk_Hqp4",
        "outputId": "f58f8d3d-5c5b-4ecb-977e-c79681d356c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[INST]Paraphrase the following user story: A researcher in computational biology is using backpropagation to train a machine learning algorithm to predict the likelihood of different genetic mutations leading to cancer. By analyzing large sets of genomic data, the algorithm is trained to identify the underlying genetic factors that contribute to cancer development..\\nBased on the following metrics: diff_total_characters: 9,diff_uppercase_characters: 0,diff_lowercase_characters: 8,diff_special_characters: 0,diff_numbers: 0,diff_blanks: 1,diff_number_of_words: 1,diff_average_length_of_words: 0.0453283996299722,diff_number_of_propositions: 0,diff_average_length_of_propositions: 0.5,diff_punctuation_characters: 0,diff_lowercase_words: 1,diff_uppercase_words: 0,diff_vocabulary_richness: 1,diff_number_of_urls: 0, [/INST]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RJ-JkXrKSG4",
        "outputId": "42a78e18-283d-4e1e-98ae-0d94cb73b417"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              prompt  \\\n",
            "0  Paraphrase the following user story: A researc...   \n",
            "1  Paraphrase the following user story: As a comp...   \n",
            "2  Paraphrase the following user story: As a micr...   \n",
            "3  Paraphrase the following user story: As a biol...   \n",
            "4  Paraphrase the following user story: As a bioi...   \n",
            "5  Paraphrase the following user story: As a bioi...   \n",
            "6  Paraphrase the following user story: As a medi...   \n",
            "7  Paraphrase the following user story: As a bioi...   \n",
            "8  Paraphrase the following user story: As a biol...   \n",
            "9  Paraphrase the following user story: As an evo...   \n",
            "\n",
            "                                            response  \\\n",
            "0  A computational biologist is utilizing backpro...   \n",
            "1  As a computational biologist, I want to utiliz...   \n",
            "2  As a microbiologist, I want to use constrained...   \n",
            "3  As a biologist, I want to utilize data mining ...   \n",
            "4  As a bioinformatics researcher, I want to crea...   \n",
            "5  As a bioinformatics specialist, I aim to lever...   \n",
            "6  As a medical imaging specialist, I need an eff...   \n",
            "7  As a bioinformatics researcher, I want to use ...   \n",
            "8  As a biologist, I want to utilize entity linki...   \n",
            "9  As an evolutionary biologist, I aim to leverag...   \n",
            "\n",
            "                                                text  \n",
            "0  [INST]Paraphrase the following user story: A r...  \n",
            "1  [INST]Paraphrase the following user story: As ...  \n",
            "2  [INST]Paraphrase the following user story: As ...  \n",
            "3  [INST]Paraphrase the following user story: As ...  \n",
            "4  [INST]Paraphrase the following user story: As ...  \n",
            "5  [INST]Paraphrase the following user story: As ...  \n",
            "6  [INST]Paraphrase the following user story: As ...  \n",
            "7  [INST]Paraphrase the following user story: As ...  \n",
            "8  [INST]Paraphrase the following user story: As ...  \n",
            "9  [INST]Paraphrase the following user story: As ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Merge the model and store in Google Drive"
      ],
      "metadata": {
        "id": "Ko6UkINu_qSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge and save the fine-tuned model\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/llama-2-7b-custom\"  # change to your preferred path\n",
        "\n",
        "# Reload model in FP16 and merge it with LoRA weights\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    low_cpu_mem_usage=True,\n",
        "    return_dict=True,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=device_map,\n",
        ")\n",
        "model = PeftModel.from_pretrained(base_model, new_model)\n",
        "model = model.merge_and_unload()\n",
        "\n",
        "# Reload tokenizer to save it\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"\n",
        "\n",
        "# Save the merged model\n",
        "model.save_pretrained(model_path)\n",
        "tokenizer.save_pretrained(model_path)"
      ],
      "metadata": {
        "id": "AgKCL7fTyp9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load a fine-tuned model from Drive and run inference"
      ],
      "metadata": {
        "id": "do-dFdE5zWGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/llama-2-7b-custom\"  # change to the path where your model is saved\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)"
      ],
      "metadata": {
        "id": "xg6nHPsLzMw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "prompt = \"What is 2 + 2?\"  # change to your desired prompt\n",
        "gen = pipeline('text-generation', model=model, tokenizer=tokenizer)\n",
        "result = gen(prompt)\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "id": "fBK2aE2KzZ05"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3a4da5b74c8b4664aa39728156939af4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62da50fe09b0444cbfba1015dff337d3",
              "IPY_MODEL_851b2eede2cb4020a730bf1ac23013fb",
              "IPY_MODEL_6310ebcb68e24bd9a07f05fc7ac7b70b"
            ],
            "layout": "IPY_MODEL_754ebc1751894ee7ae333948dc1eed19"
          }
        },
        "62da50fe09b0444cbfba1015dff337d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e2aafb99c714befb63b329774291141",
            "placeholder": "​",
            "style": "IPY_MODEL_4888364854a548f7bccf997da151c0b8",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "851b2eede2cb4020a730bf1ac23013fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fdbbbb08d1447d4a5457011433283cc",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ea9b66de5434b6c859de40ebf248a52",
            "value": 2
          }
        },
        "6310ebcb68e24bd9a07f05fc7ac7b70b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b291b073477449098884b5bb65b7e959",
            "placeholder": "​",
            "style": "IPY_MODEL_eb49b88252ab441dabf857d64382a1d7",
            "value": " 2/2 [01:00&lt;00:00, 27.57s/it]"
          }
        },
        "754ebc1751894ee7ae333948dc1eed19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e2aafb99c714befb63b329774291141": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4888364854a548f7bccf997da151c0b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fdbbbb08d1447d4a5457011433283cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ea9b66de5434b6c859de40ebf248a52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b291b073477449098884b5bb65b7e959": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb49b88252ab441dabf857d64382a1d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ea9b554a38749fc817db6ab539f5350": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee649089e162496b9e16561278f44208",
              "IPY_MODEL_f3660101f5464ac5be3e328ca56b22e4",
              "IPY_MODEL_42149efd68474a75906d55bb91c82343"
            ],
            "layout": "IPY_MODEL_c5481eb72f0d4c88b603a757eead5f82"
          }
        },
        "ee649089e162496b9e16561278f44208": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_daaa3c804e424e51ada07e23eed13d4d",
            "placeholder": "​",
            "style": "IPY_MODEL_a000807da3fc4f57875fada392b37d49",
            "value": "Map: 100%"
          }
        },
        "f3660101f5464ac5be3e328ca56b22e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d7e9b510913443cb06ba73941d4a287",
            "max": 2887,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_99549adfaa6e455eb162b8aec81ebed8",
            "value": 2887
          }
        },
        "42149efd68474a75906d55bb91c82343": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51d7a13830694dbba46975326c92d940",
            "placeholder": "​",
            "style": "IPY_MODEL_c8e2fc07d1d241c8b2020b7079b29868",
            "value": " 2887/2887 [00:02&lt;00:00, 1071.05 examples/s]"
          }
        },
        "c5481eb72f0d4c88b603a757eead5f82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "daaa3c804e424e51ada07e23eed13d4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a000807da3fc4f57875fada392b37d49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d7e9b510913443cb06ba73941d4a287": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99549adfaa6e455eb162b8aec81ebed8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "51d7a13830694dbba46975326c92d940": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8e2fc07d1d241c8b2020b7079b29868": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}